# PG-Drive: An high flexible open-ended driving simulator

Please install PG-Drive via:

```bash
pip install git+https://github.com/decisionforce/pg-drive.git@pre-release
```

or 

```bash
git clone https://github.com/decisionforce/pg-drive.git
cd pg-drive
git checkout pre-release
pip install -e .
```

## Quick Start

Please run `python -m pg_drive.examples.test_generalization_env` to play with the environment with keyboard!

To build the environment, you can simply run:

```python
import pg_drive  # Import this package to register the environment!
import gym

env = gym.make("GeneralizationRacing-v0", config=dict(use_render=True))
env.reset()
for i in range(1000):
    obs, reward, done, info = env.step(env.action_space.sample())
    env.render()
    if done:
        env.reset()
env.close()
```

## GeneralizationEnv Config

We do generalization experiments under the default setting of GeneralizationEnv. To reproduce our experiment results, 
no special configuration is needed.  

However, Pg-Drive can also support other research topics, and we will simply introduce the meaning of some configuration
options of GeneralizationEnv.
#### Draw Scene & Visualization


- use_render(bool): Pop a window on your screen or not

- use_rgb(bool): When you want to access the image of camera, it should be set to True. 

- force_fps(Union[int, None]): Decide the render fps. "None" means that no fps limitation. 

- debug(bool): For developing use, draw the scene with bounding box
#### Manual Control

- controller(str): "joystick" or "keyboard". Controlling vehicle by joystick is more recommended.

- manual_control(bool): Controllers above are available only when this flag is True

- use_chase_camera(bool): A perspective like racing game. usually True, when manual control 

- camera_height(float): Chase camera height

#### Traffic Config

- traffic_density(float): vehicle number per 10 meter, aiming to adjust the number of vehicle on road

- traffic_mode: trigger mode (Add_once) / reborn mode (Reborn). In Reborn mode vehicles will 
enter the map again after arriving its destination

#### Map Config

- GenerateMethod: The map can be generated by BIG according to BLOCK_NUM, BLOCK_SEQUENCE, or MAP_FILE

- GenerateConfig: A int telling BIG the total block number under BLOCK_NUM mode, or a str describing BLOCK_SEQUENCE 
(each block has a unique character severing as its ID, so combining them to get a map, the parameters of these block 
is sampled by BIG), and under MAP_FILE mode the config should be a dict describing the whole map.

#### Generalization Environment Config 

- start_seed(int): Random seed of first map.    

- environment_num(int): Number of environments. BIG generates map by a random generator initialized by a specific seed. 
Therefore, "environment_num" maps are generated by seeds \[seed for seed in range(start_seed, 
start_seed+environment_num)\]

#### Observation Config

- use_rgb(bool): If you want to use camera data, please set this to True.

- rgb_clip(bool): Squeeze the value between \[0, 255\] to \[0.0, 1.0\]

- vehicle_config(dict): Sensor parameters for vehicle

- image_buffer_name(str): decided which camera image to use (mini_map or front camera). Now we only support capture one image as a part of 
observation.

#### Action Config

- decision_repeat(int): The minimal step size of the world is 2e-2 second, and thus for agent the world will step 
decision_repeat * 2e-2 second after applying one action or step. 


#### Reward Scheme

- Coefficient of different kinds of reward to describe the driving goal

- Find more information by accessing our source code in GeneralizationEnv

- You can adjust our primitive reward function or design your own reward function

#### Etc.

- use_increment_steering(bool): Keyboard manual control is not linear, but set this value to True can use a linear 
manual control. 

- action_check(bool): Check whether the value of action computed by well-trained agent is between \[0.0, 1.0\] or not.

- pg_world_config(dict): Some basic settings for low level physics world. More information can be found in source code.

## Run on cluster

If your RL agent doesn't take images as observation and doesn't access the camera imagse, the installation procedure on cluster 
is as same as what we mentioned above; Otherwise, you have to compile Panda3d from the source code to turn 
off the X11 support.

Use the following command to build the panda3d:

```python
python ./makepanda/makepanda.py --everything --no-x11 --python-incdir your/path/to/python/include/ --python-libdir your/path/to/python/lib/ --wheel
```

It will generate a .whl file, which can be installed by pip on your cluster.
The compiling procedure can be found in [panda3d github](https://github.com/panda3d/panda3d)


